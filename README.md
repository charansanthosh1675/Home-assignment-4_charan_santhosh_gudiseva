Generative Adversarial Networks and AI Ethics 

## Student Info:
- Name: Charan santhosh gudiseva
- Student ID: 700776700  
- Course: Neural Network & Deep Learning 
 

---

## ğŸ“Œ 1. GAN Architecture

### âœ¨ Explanation:
In a **Generative Adversarial Network (GAN)**, two modelsâ€”the **generator** and **discriminator**â€”compete in a minimax game:
- **Generator (G)**: Learns to generate realistic fake data from random noise to "fool" the discriminator.
- **Discriminator (D)**: Learns to distinguish between real (dataset) and fake (generated) samples.

Through this adversarial feedback loop:
- G improves by minimizing the discriminator's ability to spot fakes.
- D improves by correctly classifying real vs. fake data.

## âš–ï¸ 2. Ethics and AI Harm

### Scenario: *Misinformation in Medical Chatbots*

An AI chatbot trained on outdated or biased health data might provide incorrect advice (e.g., recommending home remedies for severe conditions). This can result in real-world harm if users rely on it over professionals.

### âœ… Mitigation Strategies:
1. **Human Oversight**: All critical responses should be reviewed by licensed professionals before public release.
2. **Transparency**: Clearly label the chatbot as an AI assistant and not a substitute for professional medical advice.

---

## ğŸ’» 3. Programming Task â€“ Basic GAN (MNIST)

### âœ… Libraries Used:
- PyTorch
- torchvision
- matplotlib

### ğŸ§± Architecture:
- Generator: Fully connected layers with ReLU + Tanh
- Discriminator: Fully connected layers with LeakyReLU + Sigmoid

### ğŸ” Training:
- Trained for 100 epochs
- Generator and Discriminator loss monitored

### ğŸ“Š Loss Plots:

![Loss Plot](images/gan_loss_plot.png)

### ğŸ–¼ï¸ Sample Outputs:
- Epoch 0: `images/sample_epoch_0.png`  
- Epoch 50: `images/sample_epoch_50.png`  
- Epoch 100: `images/sample_epoch_100.png`

---

## ğŸ§ª 4. Programming Task â€“ Data Poisoning Simulation

### ğŸ“˜ Task:
Trained a sentiment analysis classifier on IMDB/Movie Reviews dataset. Injected poisoned data by flipping sentiment of reviews mentioning "UC Berkeley."

### ğŸ” Classifier: Logistic Regression using TF-IDF features.

### ğŸ“Š Before Poisoning:
- Accuracy: 89%
- Confusion Matrix:

![Before](images/confusion_before.png)

### ğŸ“Š After Poisoning:
- Accuracy: 74%
- Confusion Matrix:

![After](images/confusion_after.png)

### âš ï¸ Observations:
- Sharp drop in precision for "positive" class.
- Increased misclassification of targeted reviews.

---

## âš–ï¸ 5. Legal & Ethical Implications of GenAI

### âš ï¸ Issue 1: Memorizing Private Data
- **Legal**: Violates GDPR/CCPA by storing identifiable info.
- **Ethical**: Undermines consent and privacy norms.

### âš ï¸ Issue 2: Generating Copyrighted Content
- **Legal**: Breaches U.S. Copyright Law.
- **Ethical**: Disrespects original creator rights and royalties.

### âœ… Conclusion:
**Yes**, generative models should avoid training on sensitive or copyrighted data. Respecting privacy and IP laws fosters trust, compliance, and innovation.

---

## ğŸ“ˆ 6. Bias & Fairness Tools â€“ Aequitas

### ğŸ” Metric: False Negative Rate (FNR) Parity

#### What it Measures:
Ensures different groups (e.g., gender, race) have equal false negatives.

#### Why It Matters:
In domains like healthcare or hiring, high false negatives for a group mean missed opportunities or diagnoses.

#### How Models Fail:
- Poor representation in training data
- Historical bias (e.g., biased hiring records)
